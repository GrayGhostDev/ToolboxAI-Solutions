# Multi-stage Dockerfile for Celery Workers and Monitoring
# ========================================================
# Builds optimized containers for:
# - Celery Worker: Background task processing
# - Celery Beat: Periodic task scheduling
# - Flower: Real-time monitoring dashboard
# - Metrics Exporter: Prometheus metrics collection

# ========================================
# BASE STAGE - Common dependencies
# ========================================
FROM python:3.12-slim as base

# Set environment variables
ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1 \
    PYTHONHASHSEED=random \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    procps \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean

# Create non-root user for security
RUN groupadd -r celery && useradd -r -g celery -u 1003 celery

# Create application directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY apps/backend/ ./apps/backend/
COPY toolboxai_settings/ ./toolboxai_settings/

# Create necessary directories
RUN mkdir -p /var/log/celery /tmp /app/celerybeat-schedule \
    && chown -R celery:celery /var/log/celery /tmp /app/celerybeat-schedule

# ========================================
# WORKER STAGE - Celery Worker
# ========================================
FROM base as worker

# Install additional worker dependencies
RUN pip install --no-cache-dir \
    prometheus-client==0.20.0 \
    psutil>=5.9,<6

# Switch to non-root user
USER celery

# Set working directory
WORKDIR /app

# Health check for worker
HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD celery -A apps.backend.workers.celery_app inspect ping || exit 1

# Default command (can be overridden)
CMD ["celery", "-A", "apps.backend.workers.celery_app", "worker", \
     "--loglevel=INFO", "--concurrency=4", "--pool=prefork"]

# ========================================
# BEAT STAGE - Celery Beat Scheduler
# ========================================
FROM base as beat

# Switch to non-root user
USER celery

# Set working directory
WORKDIR /app

# Health check for beat
HEALTHCHECK --interval=60s --timeout=10s --start-period=30s --retries=3 \
    CMD pgrep -f "celery.*beat" || exit 1

# Default command
CMD ["celery", "-A", "apps.backend.workers.celery_app", "beat", \
     "--loglevel=INFO", "--schedule=/app/celerybeat-schedule/celerybeat-schedule.db"]

# ========================================
# FLOWER STAGE - Monitoring Dashboard
# ========================================
FROM base as flower

# Install Flower
RUN pip install --no-cache-dir flower==2.0.1

# Create flower user
RUN useradd -r -u 1004 flower

# Switch to flower user
USER flower

# Set working directory
WORKDIR /app

# Health check for Flower
HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD curl -f http://localhost:5555/api/workers || exit 1

# Default command
CMD ["celery", "-A", "apps.backend.workers.celery_app", "flower", \
     "--port=5555", "--basic_auth=admin:password"]

# ========================================
# EXPORTER STAGE - Prometheus Metrics
# ========================================
FROM base as exporter

# Install monitoring dependencies
RUN pip install --no-cache-dir \
    prometheus-client==0.20.0 \
    celery-prometheus-exporter==1.8.0

# Create exporter user
RUN useradd -r -u 1005 exporter

# Copy monitoring scripts
COPY apps/backend/workers/monitoring/ ./apps/backend/workers/monitoring/

# Switch to exporter user
USER exporter

# Set working directory
WORKDIR /app

# Health check for exporter
HEALTHCHECK --interval=30s --timeout=5s --start-period=20s --retries=3 \
    CMD curl -f http://localhost:9540/metrics || exit 1

# Default command
CMD ["python", "-m", "apps.backend.workers.monitoring.celery_exporter", \
     "--port=9540", "--interval=15"]

# ========================================
# DEVELOPMENT STAGE - Hot reload support
# ========================================
FROM base as development

# Install development dependencies
RUN pip install --no-cache-dir \
    watchdog[watchmedo]==4.0.0 \
    celery[debug]==5.4.0

# Install debugging tools
RUN pip install --no-cache-dir \
    ipdb==0.13.13 \
    pdbpp

# Switch to celery user
USER celery

# Set working directory
WORKDIR /app

# Development command with hot reload
CMD ["watchmedo", "auto-restart", "--directory=/app", "--pattern=*.py", \
     "--recursive", "--", "celery", "-A", "apps.backend.workers.celery_app", \
     "worker", "--loglevel=DEBUG", "--concurrency=2", "--pool=solo"]

# ========================================
# LABELS AND METADATA
# ========================================
LABEL maintainer="ToolBoxAI Team" \
      version="1.0.0" \
      description="Celery workers and monitoring for ToolBoxAI platform" \
      org.opencontainers.image.source="https://github.com/toolboxai/platform" \
      org.opencontainers.image.vendor="ToolBoxAI Solutions" \
      org.opencontainers.image.title="ToolBoxAI Celery Workers" \
      org.opencontainers.image.description="Background task processing with Redis and monitoring" \
      org.opencontainers.image.version="1.0.0"