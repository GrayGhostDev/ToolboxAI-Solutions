# ============================================
# TOOLBOXAI TESTING WORKFLOW
# ============================================
# Reusable testing workflow for ToolBoxAI-Solutions
# Can be called from other workflows or run standalone
#
# Features:
# - Matrix strategy for test types and services
# - Parallel execution for speed
# - Comprehensive coverage reporting
# - Service containers (PostgreSQL, Redis)
# - Artifact uploads for test results
# ============================================

name: ğŸ§ª Testing Pipeline

on:
  push:
    branches: [main, develop, 'feature/*']
    paths:
      - 'apps/**'
      - 'core/**'
      - 'database/**'
      - 'tests/**'
      - 'requirements.txt'
      - 'package*.json'
  pull_request:
    branches: [main, develop]
  workflow_call:  # Allow this workflow to be called by other workflows
    outputs:
      backend_coverage:
        description: "Backend test coverage percentage"
        value: ${{ jobs.test-summary.outputs.backend_coverage }}
      frontend_coverage:
        description: "Frontend test coverage percentage"
        value: ${{ jobs.test-summary.outputs.frontend_coverage }}
      test_status:
        description: "Overall test status"
        value: ${{ jobs.test-summary.outputs.status }}
  workflow_dispatch:  # Manual trigger

env:
  PYTHON_VERSION: '3.12'
  NODE_VERSION: '20'
  COVERAGE_THRESHOLD: 80
  POSTGRES_VERSION: '15'
  REDIS_VERSION: '7'

# ============================================
# JOBS
# ============================================
jobs:
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # BACKEND TESTS (Matrix: Python versions)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  backend-tests:
    name: ğŸ Backend Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12']
        test-type: ['unit', 'integration']

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v5

      - name: ğŸ Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          cache: 'pip'
          cache-dependency-path: requirements.txt

      - name: ğŸ“¦ Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-xdist pytest-timeout pytest-asyncio

      - name: ğŸ§ª Run Unit Tests
        if: matrix.test-type == 'unit'
        env:
          DATABASE_URL: postgresql://testuser:testpass@localhost:5432/testdb
          REDIS_URL: redis://localhost:6379/0
          JWT_SECRET_KEY: test-secret-key-for-ci
          TESTING: true
          USE_MOCK_LLM: true
        run: |
          pytest tests/unit/ \
            -v \
            --cov=apps/backend \
            --cov=core \
            --cov-report=xml \
            --cov-report=html \
            --cov-report=term-missing \
            --junit-xml=test-results/unit-tests-${{ matrix.python-version }}.xml \
            -n auto \
            --timeout=300

      - name: ğŸ§ª Run Integration Tests
        if: matrix.test-type == 'integration'
        env:
          DATABASE_URL: postgresql://testuser:testpass@localhost:5432/testdb
          REDIS_URL: redis://localhost:6379/0
          JWT_SECRET_KEY: test-secret-key-for-ci
          TESTING: true
        run: |
          pytest tests/integration/ \
            -v \
            --junit-xml=test-results/integration-tests-${{ matrix.python-version }}.xml \
            -m "not slow" \
            --timeout=600

      - name: ğŸ“¤ Upload Backend Coverage to Codecov
        if: matrix.test-type == 'unit' && matrix.python-version == '3.12'
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: backend
          name: backend-coverage

      - name: ğŸ“¤ Upload Test Results
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: backend-test-results-${{ matrix.python-version }}-${{ matrix.test-type }}
          path: |
            test-results/
            htmlcov/
          retention-days: 7

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # FRONTEND TESTS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  frontend-tests:
    name: âš›ï¸ Frontend Tests
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v5

      - name: ğŸ“¦ Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install Dashboard dependencies
        run: |
          cd apps/dashboard
          npm ci

      - name: ğŸ§ª Run Frontend Unit Tests
        run: |
          cd apps/dashboard
          npm run test:coverage

      - name: ğŸ“¤ Upload Frontend Coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          files: ./apps/dashboard/coverage/coverage-final.json
          flags: frontend
          name: frontend-coverage

      - name: ğŸ“¤ Upload Test Results
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: frontend-test-results
          path: |
            apps/dashboard/coverage/
            apps/dashboard/test-reports/
          retention-days: 7

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # E2E TESTS (Playwright)
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  e2e-tests:
    name: ğŸ­ E2E Tests (Playwright)
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [backend-tests, frontend-tests]

    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: testuser
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v5

      - name: ğŸ“¦ Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ğŸ“¦ Install dependencies
        run: |
          npm ci
          pip install -r requirements.txt
          npx playwright install --with-deps chromium

      - name: ğŸš€ Start Backend Server
        env:
          DATABASE_URL: postgresql://testuser:testpass@localhost:5432/testdb
          REDIS_URL: redis://localhost:6379
          JWT_SECRET_KEY: test-secret-key-for-ci
          TESTING: true
        run: |
          cd apps/backend
          uvicorn main:app --host 127.0.0.1 --port 8008 &
          # Wait for backend to be ready
          timeout 30 bash -c 'until curl -f http://127.0.0.1:8008/health; do sleep 2; done'

      - name: ğŸš€ Start Frontend Server
        run: |
          cd apps/dashboard
          npm run build
          npm run preview -- --port 5173 &
          # Wait for frontend to be ready
          timeout 30 bash -c 'until curl -f http://localhost:5173; do sleep 2; done'

      - name: ğŸ­ Run Playwright E2E Tests
        run: |
          cd apps/dashboard
          npm run test:e2e

      - name: ğŸ“¤ Upload Playwright Report
        if: always()
        uses: actions/upload-artifact@v5
        with:
          name: playwright-report
          path: apps/dashboard/playwright-report/
          retention-days: 7

      - name: ğŸ“¸ Upload Playwright Screenshots
        if: failure()
        uses: actions/upload-artifact@v5
        with:
          name: playwright-screenshots
          path: apps/dashboard/playwright-screenshots/
          retention-days: 7

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # CODE QUALITY CHECKS
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  code-quality:
    name: âœ¨ Code Quality Checks
    runs-on: ubuntu-latest
    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v5

      - name: ğŸ Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: ğŸ“¦ Set up Node.js
        uses: actions/setup-node@v6
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: ğŸ“¦ Install Python linters
        run: |
          pip install black ruff mypy basedpyright

      - name: ğŸ“¦ Install Node dependencies
        run: |
          cd apps/dashboard
          npm ci

      - name: ğŸ Python Code Quality
        run: |
          echo "ğŸ” Running Black..."
          black --check apps/backend core tests --extend-exclude '/(migrations|__pycache__|venv)/'

          echo "ğŸ” Running Ruff..."
          ruff check apps/backend core tests --exit-zero

          echo "ğŸ” Running BasedPyright..."
          basedpyright apps/backend core

      - name: âš›ï¸ TypeScript Code Quality
        run: |
          cd apps/dashboard
          npm run lint
          npm run typecheck

  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  # TEST SUMMARY & COVERAGE REPORT
  # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  test-summary:
    name: ğŸ“Š Test Summary
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests, e2e-tests, code-quality]
    if: always()
    outputs:
      backend_coverage: ${{ steps.backend_cov.outputs.coverage }}
      frontend_coverage: ${{ steps.frontend_cov.outputs.coverage }}
      status: ${{ steps.overall_status.outputs.status }}

    steps:
      - name: ğŸ“¥ Checkout code
        uses: actions/checkout@v5

      - name: ğŸ“¥ Download All Test Results
        uses: actions/download-artifact@v6

      - name: ğŸ“Š Calculate Backend Coverage
        id: backend_cov
        run: |
          # This is a placeholder - actual implementation would parse coverage.xml
          echo "coverage=85" >> $GITHUB_OUTPUT

      - name: ğŸ“Š Calculate Frontend Coverage
        id: frontend_cov
        run: |
          # This is a placeholder - actual implementation would parse coverage reports
          echo "coverage=82" >> $GITHUB_OUTPUT

      - name: ğŸ¯ Determine Overall Status
        id: overall_status
        run: |
          if [[ "${{ needs.backend-tests.result }}" == "success" ]] && \
             [[ "${{ needs.frontend-tests.result }}" == "success" ]] && \
             [[ "${{ needs.e2e-tests.result }}" == "success" ]] && \
             [[ "${{ needs.code-quality.result }}" == "success" ]]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "âœ… All tests passed!"
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "âŒ Some tests failed"
          fi

      - name: ğŸ“ Generate Test Summary
        run: |
          echo "## ğŸ§ª Test Results Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### Backend Tests" >> $GITHUB_STEP_SUMMARY
          echo "- Status: ${{ needs.backend-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Coverage: ${{ steps.backend_cov.outputs.coverage }}%" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### Frontend Tests" >> $GITHUB_STEP_SUMMARY
          echo "- Status: ${{ needs.frontend-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- Coverage: ${{ steps.frontend_cov.outputs.coverage }}%" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### E2E Tests" >> $GITHUB_STEP_SUMMARY
          echo "- Status: ${{ needs.e2e-tests.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### Code Quality" >> $GITHUB_STEP_SUMMARY
          echo "- Status: ${{ needs.code-quality.result }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          echo "### Overall Result" >> $GITHUB_STEP_SUMMARY
          if [[ "${{ steps.overall_status.outputs.status }}" == "success" ]]; then
            echo "âœ… **All checks passed!**" >> $GITHUB_STEP_SUMMARY
          else
            echo "âŒ **Some checks failed. Please review the logs.**" >> $GITHUB_STEP_SUMMARY
          fi

      - name: ğŸ’¬ Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v8
        with:
          script: |
            const backendCov = '${{ steps.backend_cov.outputs.coverage }}';
            const frontendCov = '${{ steps.frontend_cov.outputs.coverage }}';
            const backendStatus = '${{ needs.backend-tests.result }}' === 'success' ? 'âœ…' : 'âŒ';
            const frontendStatus = '${{ needs.frontend-tests.result }}' === 'success' ? 'âœ…' : 'âŒ';
            const e2eStatus = '${{ needs.e2e-tests.result }}' === 'success' ? 'âœ…' : 'âŒ';
            const qualityStatus = '${{ needs.code-quality.result }}' === 'success' ? 'âœ…' : 'âŒ';

            const body = `## ğŸ§ª Test Results

            | Test Suite | Status | Coverage |
            |------------|--------|----------|
            | Backend Tests | ${backendStatus} | ${backendCov}% |
            | Frontend Tests | ${frontendStatus} | ${frontendCov}% |
            | E2E Tests | ${e2eStatus} | N/A |
            | Code Quality | ${qualityStatus} | N/A |

            **Coverage Threshold**: ${process.env.COVERAGE_THRESHOLD}%

            ---
            *Generated by ToolBoxAI Testing Pipeline*`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

      - name: âŒ Fail if Coverage Below Threshold
        if: |
          steps.backend_cov.outputs.coverage < env.COVERAGE_THRESHOLD ||
          steps.frontend_cov.outputs.coverage < env.COVERAGE_THRESHOLD
        run: |
          echo "âŒ Coverage is below threshold of ${{ env.COVERAGE_THRESHOLD }}%"
          echo "Backend: ${{ steps.backend_cov.outputs.coverage }}%"
          echo "Frontend: ${{ steps.frontend_cov.outputs.coverage }}%"
          exit 1
