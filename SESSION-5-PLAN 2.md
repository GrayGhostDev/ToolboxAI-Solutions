# Session 5: Testing & Quality Excellence

**Date:** 2025-10-10
**Branch:** `feat/testing-quality-improvements`
**Status:** ðŸ“‹ PLANNED
**Priority:** CRITICAL - Production Blocker

## Executive Summary

Session 5 focuses on comprehensive testing and quality improvements to achieve production readiness. Based on TODO.md Week 4 priorities, this session will increase test coverage from ~60% to 80%+, standardize error handling across 1,811 generic exception handlers, and implement robust testing infrastructure.

### Goals

| Metric | Current | Target | Priority |
|--------|---------|--------|----------|
| Test Coverage | ~60% | 80%+ | CRITICAL |
| Tests per Endpoint | 0.73 (272/350) | 2.0+ | CRITICAL |
| Generic Exceptions | 1,811 | <100 | HIGH |
| E2E Test Coverage | 0% | 50%+ | HIGH |
| Test Execution Time | Unknown | <5 min | MEDIUM |

### Success Criteria

- âœ… Backend test coverage â‰¥80%
- âœ… Frontend test coverage â‰¥75%
- âœ… All critical paths have integration tests
- âœ… E2E tests cover main user flows
- âœ… <100 generic exception handlers remain
- âœ… Test execution time <5 minutes
- âœ… Coverage reports automated in CI/CD

---

## ðŸ“Š Current State Analysis

### Test Inventory

```yaml
Backend Tests:
  Total Files: 272
  Unit Tests: ~180
  Integration Tests: ~60
  E2E Tests: ~20
  Security Tests: 50+
  Locations:
    - tests/unit/ (core, backend, services)
    - tests/integration/ (api, database, agents)
    - tests/e2e/ (workflows, user journeys)
    - tests/security/ (authentication, authorization, pii)

Frontend Tests:
  Total Files: 49
  Component Tests: ~35
  Integration Tests: ~10
  E2E Tests: ~4
  Location: apps/dashboard/src/__tests__/

Test Framework:
  Backend: pytest 8.x with pytest-asyncio, pytest-cov
  Frontend: Vitest 3.x with React Testing Library
  E2E: Playwright (partially configured)

Coverage:
  Backend: ~60% (estimated from file analysis)
  Frontend: ~45% (estimated from test count)
  Critical Paths: ~40% (major gaps identified)
```

### Testing Gaps Identified

#### 1. **Backend Router Coverage** (CRITICAL GAP)

Missing unit tests for critical routers:

```python
Missing Coverage:
apps/backend/routers/
  â”œâ”€â”€ content.py          # âŒ 0% coverage - 15+ endpoints
  â”œâ”€â”€ analytics.py        # âŒ 0% coverage - 8 endpoints
  â”œâ”€â”€ roblox_integration.py # âŒ 0% coverage - 12 endpoints
  â”œâ”€â”€ admin.py            # âŒ 10% coverage - 20 endpoints
  â”œâ”€â”€ payments.py         # âš ï¸ 30% coverage - 18 endpoints
  â”œâ”€â”€ notifications.py    # âš ï¸ 25% coverage - 9 endpoints
  â””â”€â”€ user_profile.py     # âœ… 75% coverage - 6 endpoints

Critical Paths Without Tests:
  - Content generation workflow (content.py:145-289)
  - Payment subscription flow (payments.py:67-234)
  - Roblox asset deployment (roblox_integration.py:189-456)
  - Analytics aggregation (analytics.py:34-178)
```

#### 2. **Frontend Component Coverage** (CRITICAL GAP)

Missing tests for 50+ components:

```typescript
Missing Coverage:
apps/dashboard/src/components/
  â”œâ”€â”€ AgentDashboard/       # âŒ 0% - Complex state management
  â”œâ”€â”€ ContentGenerator/     # âŒ 0% - AI integration
  â”œâ”€â”€ PaymentForms/         # âŒ 0% - Stripe integration
  â”œâ”€â”€ RobloxIntegration/    # âŒ 0% - Game state sync
  â”œâ”€â”€ AnalyticsDashboard/   # âš ï¸ 20% - 3/15 components
  â””â”€â”€ Settings/             # âš ï¸ 40% - 4/10 components

Critical User Flows Without Tests:
  - User registration and onboarding
  - Content creation and publishing
  - Payment and subscription management
  - Roblox game integration
```

#### 3. **Integration Test Gaps** (HIGH GAP)

Missing workflow integration tests:

```yaml
Missing Workflows:
  - User Authentication Flow:
      - Registration â†’ Email Verification â†’ Profile Setup
      - Login â†’ MFA â†’ Dashboard Access
      - Password Reset â†’ Email Link â†’ New Password

  - Content Creation Flow:
      - Create Content â†’ AI Generation â†’ Review â†’ Publish
      - Schedule Content â†’ Queue Job â†’ Celery Task â†’ Roblox Deploy

  - Payment Flow:
      - Select Plan â†’ Stripe Checkout â†’ Webhook â†’ Provision Access
      - Subscription Renewal â†’ Payment Method â†’ Invoice Generation
      - Payment Failure â†’ Dunning System â†’ User Notification

  - Roblox Integration Flow:
      - Connect Game â†’ Authenticate â†’ Sync Assets
      - Deploy Update â†’ Version Control â†’ Rollback Capability
```

#### 4. **E2E Test Gaps** (HIGH GAP)

Current E2E coverage is minimal (~20 tests in tests/e2e/). Need comprehensive user journey tests:

```typescript
Missing E2E Scenarios:
  1. Complete User Journey:
     - New user signs up
     - Verifies email
     - Creates first content
     - Publishes to Roblox
     - Views analytics

  2. Admin Workflow:
     - Admin login
     - User management
     - Content moderation
     - Analytics review

  3. Payment Journey:
     - Free trial signup
     - Upgrade to paid
     - Manage subscription
     - Handle payment failure

  4. Error Recovery:
     - API failure â†’ Retry
     - Payment declined â†’ Dunning
     - Deployment failed â†’ Rollback
```

#### 5. **Error Handling Quality** (CRITICAL GAP)

**1,811 Generic Exception Handlers** identified:

```python
Top Offenders:
  1. apps/backend/main.py - 47 generic exceptions
  2. core/agents/orchestrator.py - 89 generic exceptions
  3. apps/backend/services/pusher_handler.py - 23 generic exceptions
  4. apps/backend/routers/content.py - 34 generic exceptions
  5. core/sparc/sparc_engine.py - 56 generic exceptions

Pattern Example (NEEDS FIXING):
# BAD - Generic exception
try:
    result = await api_call()
except Exception as e:  # âŒ Too broad
    logger.error(f"Error: {e}")
    return None

# GOOD - Specific exceptions
try:
    result = await api_call()
except asyncio.TimeoutError:  # âœ… Specific
    logger.error("API timeout", extra={"endpoint": endpoint})
    raise HTTPException(status_code=504, detail="Gateway Timeout")
except httpx.HTTPStatusError as e:  # âœ… Specific
    logger.error("API error", extra={"status": e.response.status_code})
    raise HTTPException(status_code=e.response.status_code)
except Exception as e:  # âœ… Last resort with re-raise
    logger.exception("Unexpected error")
    raise
```

---

## ðŸŽ¯ Session 5 Deliverables

### Deliverable 1: Testing Infrastructure Enhancement

**Goal:** Establish robust testing foundation with modern tools and patterns

#### Files to Create/Update:

```yaml
1. Test Configuration:
   - tests/pytest.ini (enhanced configuration)
   - tests/.coveragerc (coverage settings)
   - tests/conftest.py (global fixtures - UPDATE)
   - apps/dashboard/vitest.config.ts (frontend config - UPDATE)

2. Test Utilities:
   - tests/utils/factories.py (test data factories)
   - tests/utils/fixtures.py (reusable fixtures)
   - tests/utils/assertions.py (custom assertions)
   - tests/utils/mocks.py (mock services)

3. CI/CD Integration:
   - .github/workflows/test-coverage.yml (coverage reporting)
   - .github/workflows/test-quality.yml (mutation testing)
   - scripts/testing/run_coverage.sh (local coverage script)
   - scripts/testing/generate_report.py (coverage report generator)
```

**Tasks:**
- [x] Enhance pytest configuration with plugins (pytest-cov, pytest-xdist, pytest-timeout)
- [x] Set up coverage reporting with HTML/XML output
- [x] Create test data factories using Factory Boy
- [x] Implement fixture library for common test scenarios
- [x] Configure parallel test execution with pytest-xdist
- [x] Add mutation testing with mutmut
- [x] Set up Vitest configuration for frontend
- [x] Create CI/CD workflows for automated testing

**Effort:** 2-3 days
**Priority:** CRITICAL

---

### Deliverable 2: Backend Unit Test Suite

**Goal:** Achieve 80%+ backend code coverage with comprehensive unit tests

#### Files to Create:

```python
Router Tests (15 new test files):
  tests/unit/backend/routers/
    â”œâ”€â”€ test_content_router.py           # Content generation endpoints
    â”œâ”€â”€ test_analytics_router.py         # Analytics endpoints
    â”œâ”€â”€ test_roblox_integration_router.py # Roblox endpoints
    â”œâ”€â”€ test_admin_router.py             # Admin endpoints
    â”œâ”€â”€ test_payments_router.py          # Payment endpoints (enhance existing)
    â”œâ”€â”€ test_notifications_router.py     # Notification endpoints
    â”œâ”€â”€ test_auth_router.py              # Authentication endpoints
    â”œâ”€â”€ test_users_router.py             # User management
    â”œâ”€â”€ test_courses_router.py           # Course management
    â”œâ”€â”€ test_lessons_router.py           # Lesson management
    â”œâ”€â”€ test_quizzes_router.py           # Quiz management
    â”œâ”€â”€ test_assignments_router.py       # Assignment management
    â”œâ”€â”€ test_media_router.py             # Media upload/serving
    â”œâ”€â”€ test_settings_router.py          # Settings management
    â””â”€â”€ test_webhooks_router.py          # Webhook handlers

Service Tests (12 new test files):
  tests/unit/backend/services/
    â”œâ”€â”€ test_content_generation_service.py
    â”œâ”€â”€ test_ai_orchestration_service.py
    â”œâ”€â”€ test_roblox_deployment_service.py
    â”œâ”€â”€ test_analytics_aggregation_service.py
    â”œâ”€â”€ test_notification_service.py
    â”œâ”€â”€ test_file_processing_service.py
    â”œâ”€â”€ test_cache_service.py
    â”œâ”€â”€ test_queue_service.py
    â”œâ”€â”€ test_tenant_service.py
    â”œâ”€â”€ test_audit_service.py
    â”œâ”€â”€ test_metrics_service.py
    â””â”€â”€ test_health_service.py

Core Tests (8 new test files):
  tests/unit/core/
    â”œâ”€â”€ test_error_handlers.py           # Custom error handlers
    â”œâ”€â”€ test_dependencies.py             # FastAPI dependencies
    â”œâ”€â”€ test_validators.py               # Input validators
    â”œâ”€â”€ test_serializers.py              # Response serializers
    â”œâ”€â”€ test_permissions.py              # Permission system
    â”œâ”€â”€ test_rate_limiting.py            # Rate limit logic
    â”œâ”€â”€ test_caching.py                  # Cache strategies
    â””â”€â”€ test_monitoring.py               # Metrics collection
```

**Test Patterns:**

```python
# Example: test_content_router.py
import pytest
from fastapi.testclient import TestClient
from unittest.mock import AsyncMock, patch

class TestContentRouter:
    """Comprehensive tests for content generation endpoints"""

    @pytest.fixture
    def mock_content_service(self):
        """Mock content generation service"""
        with patch('apps.backend.services.content_service') as mock:
            mock.generate_content = AsyncMock(return_value={
                "content_id": "test-123",
                "status": "completed",
                "result": {...}
            })
            yield mock

    @pytest.mark.asyncio
    async def test_create_content_success(
        self, client: TestClient, mock_content_service, auth_headers
    ):
        """Test successful content creation"""
        # Arrange
        payload = {
            "title": "Test Content",
            "content_type": "lesson",
            "target_audience": "grade_5"
        }

        # Act
        response = client.post(
            "/api/v1/content",
            json=payload,
            headers=auth_headers
        )

        # Assert
        assert response.status_code == 201
        assert response.json()["content_id"] == "test-123"
        mock_content_service.generate_content.assert_called_once()

    @pytest.mark.asyncio
    async def test_create_content_invalid_input(
        self, client: TestClient, auth_headers
    ):
        """Test content creation with invalid input"""
        # Arrange
        payload = {"title": ""}  # Invalid: empty title

        # Act
        response = client.post(
            "/api/v1/content",
            json=payload,
            headers=auth_headers
        )

        # Assert
        assert response.status_code == 422
        assert "validation" in response.json()["detail"].lower()

    @pytest.mark.asyncio
    async def test_create_content_unauthorized(self, client: TestClient):
        """Test content creation without authentication"""
        # Act
        response = client.post("/api/v1/content", json={})

        # Assert
        assert response.status_code == 401
```

**Coverage Goals:**
- Critical paths: 100% coverage
- Routers: 85%+ coverage
- Services: 80%+ coverage
- Core utilities: 90%+ coverage

**Effort:** 5-6 days
**Priority:** CRITICAL

---

### Deliverable 3: Frontend Component Test Suite

**Goal:** Achieve 75%+ frontend code coverage with component and integration tests

#### Files to Create:

```typescript
Component Tests (25 new test files):
  apps/dashboard/src/__tests__/components/
    â”œâ”€â”€ AgentDashboard/
    â”‚   â”œâ”€â”€ AgentList.test.tsx
    â”‚   â”œâ”€â”€ AgentDetails.test.tsx
    â”‚   â”œâ”€â”€ AgentMetrics.test.tsx
    â”‚   â””â”€â”€ AgentControls.test.tsx
    â”œâ”€â”€ ContentGenerator/
    â”‚   â”œâ”€â”€ ContentForm.test.tsx
    â”‚   â”œâ”€â”€ ContentPreview.test.tsx
    â”‚   â”œâ”€â”€ ContentPublish.test.tsx
    â”‚   â””â”€â”€ ContentHistory.test.tsx
    â”œâ”€â”€ PaymentForms/
    â”‚   â”œâ”€â”€ CheckoutForm.test.tsx
    â”‚   â”œâ”€â”€ SubscriptionManager.test.tsx
    â”‚   â”œâ”€â”€ PaymentMethod.test.tsx
    â”‚   â””â”€â”€ InvoiceList.test.tsx
    â”œâ”€â”€ RobloxIntegration/
    â”‚   â”œâ”€â”€ GameConnector.test.tsx
    â”‚   â”œâ”€â”€ AssetManager.test.tsx
    â”‚   â”œâ”€â”€ DeploymentStatus.test.tsx
    â”‚   â””â”€â”€ GamePreview.test.tsx
    â””â”€â”€ Analytics/
        â”œâ”€â”€ Dashboard.test.tsx
        â”œâ”€â”€ Charts.test.tsx
        â”œâ”€â”€ Reports.test.tsx
        â””â”€â”€ Insights.test.tsx

Hook Tests (10 new test files):
  apps/dashboard/src/__tests__/hooks/
    â”œâ”€â”€ useAuth.test.ts
    â”œâ”€â”€ useContent.test.ts
    â”œâ”€â”€ usePusher.test.ts
    â”œâ”€â”€ usePayments.test.ts
    â”œâ”€â”€ useRoblox.test.ts
    â”œâ”€â”€ useAnalytics.test.ts
    â”œâ”€â”€ useNotifications.test.ts
    â”œâ”€â”€ usePermissions.test.ts
    â”œâ”€â”€ useCache.test.ts
    â””â”€â”€ useApi.test.ts

Integration Tests (8 new test files):
  apps/dashboard/src/__tests__/integration/
    â”œâ”€â”€ AuthFlow.test.tsx
    â”œâ”€â”€ ContentWorkflow.test.tsx
    â”œâ”€â”€ PaymentFlow.test.tsx
    â”œâ”€â”€ RobloxSync.test.tsx
    â”œâ”€â”€ NotificationSystem.test.tsx
    â”œâ”€â”€ AnalyticsPipeline.test.tsx
    â”œâ”€â”€ PermissionSystem.test.tsx
    â””â”€â”€ CacheInvalidation.test.tsx
```

**Test Patterns:**

```typescript
// Example: ContentForm.test.tsx
import { render, screen, waitFor } from '@testing-library/react';
import userEvent from '@testing-library/user-event';
import { vi } from 'vitest';
import { ContentForm } from '@/components/ContentGenerator/ContentForm';

describe('ContentForm', () => {
  it('renders form fields correctly', () => {
    render(<ContentForm />);

    expect(screen.getByLabelText(/title/i)).toBeInTheDocument();
    expect(screen.getByLabelText(/content type/i)).toBeInTheDocument();
    expect(screen.getByLabelText(/target audience/i)).toBeInTheDocument();
    expect(screen.getByRole('button', { name: /generate/i })).toBeInTheDocument();
  });

  it('validates required fields', async () => {
    const user = userEvent.setup();
    render(<ContentForm />);

    const submitButton = screen.getByRole('button', { name: /generate/i });
    await user.click(submitButton);

    expect(screen.getByText(/title is required/i)).toBeInTheDocument();
    expect(screen.getByText(/content type is required/i)).toBeInTheDocument();
  });

  it('submits form with valid data', async () => {
    const user = userEvent.setup();
    const onSubmit = vi.fn();
    render(<ContentForm onSubmit={onSubmit} />);

    await user.type(screen.getByLabelText(/title/i), 'Test Content');
    await user.selectOptions(screen.getByLabelText(/content type/i), 'lesson');
    await user.selectOptions(screen.getByLabelText(/target audience/i), 'grade_5');

    await user.click(screen.getByRole('button', { name: /generate/i }));

    await waitFor(() => {
      expect(onSubmit).toHaveBeenCalledWith({
        title: 'Test Content',
        contentType: 'lesson',
        targetAudience: 'grade_5'
      });
    });
  });

  it('displays loading state during generation', async () => {
    const user = userEvent.setup();
    render(<ContentForm />);

    // Fill form
    await user.type(screen.getByLabelText(/title/i), 'Test');
    await user.click(screen.getByRole('button', { name: /generate/i }));

    expect(screen.getByText(/generating/i)).toBeInTheDocument();
    expect(screen.getByRole('button', { name: /generate/i })).toBeDisabled();
  });

  it('handles API errors gracefully', async () => {
    const user = userEvent.setup();
    const onSubmit = vi.fn().mockRejectedValue(new Error('API Error'));
    render(<ContentForm onSubmit={onSubmit} />);

    await user.type(screen.getByLabelText(/title/i), 'Test');
    await user.click(screen.getByRole('button', { name: /generate/i }));

    await waitFor(() => {
      expect(screen.getByText(/failed to generate content/i)).toBeInTheDocument();
    });
  });
});
```

**Coverage Goals:**
- Critical components: 90%+ coverage
- Forms: 85%+ coverage
- Hooks: 80%+ coverage
- Integration flows: 75%+ coverage

**Effort:** 4-5 days
**Priority:** CRITICAL

---

### Deliverable 4: E2E Testing Infrastructure

**Goal:** Implement comprehensive end-to-end testing with Playwright

#### Files to Create:

```typescript
Playwright Configuration:
  playwright.config.ts (enhanced configuration)
  tests/e2e/
    â”œâ”€â”€ fixtures/
    â”‚   â”œâ”€â”€ test-users.ts         # Pre-configured test users
    â”‚   â”œâ”€â”€ test-data.ts          # Test data generators
    â”‚   â””â”€â”€ page-objects.ts       # Page object models
    â”œâ”€â”€ helpers/
    â”‚   â”œâ”€â”€ auth.ts               # Authentication helpers
    â”‚   â”œâ”€â”€ api.ts                # API interaction helpers
    â”‚   â””â”€â”€ assertions.ts         # Custom assertions
    â””â”€â”€ specs/
        â”œâ”€â”€ user-journey/
        â”‚   â”œâ”€â”€ registration.spec.ts
        â”‚   â”œâ”€â”€ onboarding.spec.ts
        â”‚   â”œâ”€â”€ content-creation.spec.ts
        â”‚   â”œâ”€â”€ payment-flow.spec.ts
        â”‚   â””â”€â”€ roblox-integration.spec.ts
        â”œâ”€â”€ admin-workflow/
        â”‚   â”œâ”€â”€ user-management.spec.ts
        â”‚   â”œâ”€â”€ content-moderation.spec.ts
        â”‚   â”œâ”€â”€ analytics-review.spec.ts
        â”‚   â””â”€â”€ system-settings.spec.ts
        â”œâ”€â”€ error-recovery/
        â”‚   â”œâ”€â”€ api-failure.spec.ts
        â”‚   â”œâ”€â”€ payment-declined.spec.ts
        â”‚   â””â”€â”€ deployment-rollback.spec.ts
        â””â”€â”€ accessibility/
            â”œâ”€â”€ keyboard-navigation.spec.ts
            â”œâ”€â”€ screen-reader.spec.ts
            â””â”€â”€ color-contrast.spec.ts
```

**Test Example:**

```typescript
// registration.spec.ts
import { test, expect } from '@playwright/test';

test.describe('User Registration Journey', () => {
  test('complete registration flow', async ({ page }) => {
    // Navigate to signup
    await page.goto('/signup');

    // Fill registration form
    await page.getByLabel('Email').fill('test@example.com');
    await page.getByLabel('Password').fill('SecurePass123!');
    await page.getByLabel('Confirm Password').fill('SecurePass123!');
    await page.getByRole('button', { name: 'Sign Up' }).click();

    // Verify email verification message
    await expect(page.getByText(/verification email sent/i)).toBeVisible();

    // Simulate email verification (via API)
    const verificationToken = await page.evaluate(() => {
      return window.localStorage.getItem('verification_token');
    });
    await page.goto(`/verify-email?token=${verificationToken}`);

    // Complete profile setup
    await expect(page.getByText(/complete your profile/i)).toBeVisible();
    await page.getByLabel('First Name').fill('John');
    await page.getByLabel('Last Name').fill('Doe');
    await page.getByLabel('Role').selectOption('Teacher');
    await page.getByRole('button', { name: 'Continue' }).click();

    // Verify dashboard access
    await expect(page).toHaveURL('/dashboard');
    await expect(page.getByText(/welcome, john/i)).toBeVisible();
  });

  test('validates email format', async ({ page }) => {
    await page.goto('/signup');
    await page.getByLabel('Email').fill('invalid-email');
    await page.getByLabel('Password').fill('password');
    await page.getByRole('button', { name: 'Sign Up' }).click();

    await expect(page.getByText(/invalid email format/i)).toBeVisible();
  });

  test('prevents duplicate registration', async ({ page }) => {
    // Try to register with existing email
    await page.goto('/signup');
    await page.getByLabel('Email').fill('existing@example.com');
    await page.getByLabel('Password').fill('password');
    await page.getByRole('button', { name: 'Sign Up' }).click();

    await expect(page.getByText(/email already registered/i)).toBeVisible();
  });
});
```

**Coverage Goals:**
- 50%+ of critical user journeys
- All major workflows tested
- Error scenarios covered
- Accessibility compliance verified

**Effort:** 3-4 days
**Priority:** HIGH

---

### Deliverable 5: Error Handling Standardization

**Goal:** Replace 1,811 generic exception handlers with specific, actionable error handling

#### Files to Create/Update:

```python
Custom Exception Hierarchy:
  apps/backend/core/exceptions/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ base.py                   # BaseAPIException
    â”œâ”€â”€ auth.py                   # AuthenticationError, AuthorizationError
    â”œâ”€â”€ validation.py             # ValidationError, SchemaError
    â”œâ”€â”€ database.py               # DatabaseError, NotFoundError
    â”œâ”€â”€ external.py               # ExternalServiceError, TimeoutError
    â”œâ”€â”€ business.py               # BusinessLogicError, PermissionDenied
    â””â”€â”€ handlers.py               # Exception handlers for FastAPI

Error Handling Middleware:
  apps/backend/middleware/error_handler.py (enhanced)

Error Recovery:
  apps/backend/core/retry/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ strategies.py             # Retry strategies
    â”œâ”€â”€ circuit_breaker.py        # Circuit breaker pattern
    â””â”€â”€ fallback.py               # Fallback mechanisms

Documentation:
  docs/ERROR_HANDLING_GUIDE.md
```

**Custom Exception Example:**

```python
# apps/backend/core/exceptions/base.py
from typing import Any, Dict, Optional
from fastapi import status

class BaseAPIException(Exception):
    """Base exception for all API errors"""

    def __init__(
        self,
        message: str,
        status_code: int = status.HTTP_500_INTERNAL_SERVER_ERROR,
        error_code: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None
    ):
        self.message = message
        self.status_code = status_code
        self.error_code = error_code or self.__class__.__name__
        self.details = details or {}
        super().__init__(self.message)

# apps/backend/core/exceptions/auth.py
from .base import BaseAPIException
from fastapi import status

class AuthenticationError(BaseAPIException):
    """Raised when authentication fails"""

    def __init__(self, message: str = "Authentication failed", **kwargs):
        super().__init__(
            message=message,
            status_code=status.HTTP_401_UNAUTHORIZED,
            **kwargs
        )

class TokenExpiredError(AuthenticationError):
    """Raised when JWT token has expired"""

    def __init__(self):
        super().__init__(
            message="Token has expired",
            error_code="TOKEN_EXPIRED"
        )

class InvalidTokenError(AuthenticationError):
    """Raised when JWT token is invalid"""

    def __init__(self):
        super().__init__(
            message="Invalid token provided",
            error_code="INVALID_TOKEN"
        )
```

**Migration Strategy:**

```python
# BEFORE - Generic exception (BAD)
@router.post("/content")
async def create_content(data: ContentCreate):
    try:
        result = await content_service.generate(data)
        return result
    except Exception as e:  # âŒ Too broad
        logger.error(f"Error: {e}")
        raise HTTPException(status_code=500, detail="Internal error")

# AFTER - Specific exceptions (GOOD)
from apps.backend.core.exceptions import (
    ValidationError,
    ExternalServiceError,
    DatabaseError
)
from apps.backend.core.retry import with_retry, exponential_backoff

@router.post("/content")
@with_retry(strategy=exponential_backoff(max_attempts=3))
async def create_content(data: ContentCreate):
    try:
        # Validate input
        if not data.title:
            raise ValidationError(
                message="Title is required",
                error_code="MISSING_TITLE",
                details={"field": "title"}
            )

        # Call external AI service with specific error handling
        try:
            result = await content_service.generate(data)
        except asyncio.TimeoutError:
            raise ExternalServiceError(
                message="AI service timeout",
                error_code="AI_TIMEOUT",
                details={"service": "openai", "timeout": 30}
            )
        except httpx.HTTPStatusError as e:
            raise ExternalServiceError(
                message="AI service error",
                error_code="AI_ERROR",
                details={"status_code": e.response.status_code}
            )

        # Save to database with specific error handling
        try:
            await db.save(result)
        except IntegrityError as e:
            raise DatabaseError(
                message="Duplicate content",
                error_code="DUPLICATE_CONTENT",
                details={"constraint": str(e)}
            )

        return result

    except BaseAPIException:
        # Re-raise our custom exceptions
        raise
    except Exception as e:
        # Last resort: log and convert to internal error
        logger.exception(
            "Unexpected error in content creation",
            extra={"data": data.dict(), "error": str(e)}
        )
        raise InternalServerError(
            message="Unexpected error occurred",
            error_code="INTERNAL_ERROR"
        )
```

**Migration Targets:**

```yaml
Phase 1 - Critical Paths (Week 1):
  - apps/backend/routers/content.py (34 â†’ 0)
  - apps/backend/routers/payments.py (28 â†’ 0)
  - apps/backend/services/stripe_service.py (19 â†’ 0)
  - Target: 150 exceptions fixed

Phase 2 - Core Services (Week 2):
  - core/agents/orchestrator.py (89 â†’ 0)
  - core/sparc/sparc_engine.py (56 â†’ 0)
  - apps/backend/services/pusher_handler.py (23 â†’ 0)
  - Target: 300 exceptions fixed

Phase 3 - Remaining (Week 3):
  - All other files with >10 generic exceptions
  - Target: All 1811 â†’ <100
```

**Effort:** 4-5 days (incremental with other deliverables)
**Priority:** HIGH

---

### Deliverable 6: Test Data Factories

**Goal:** Create reusable test data factories for consistent, maintainable tests

#### Files to Create:

```python
Factory Implementation:
  tests/utils/factories/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ user_factory.py           # User and auth factories
    â”œâ”€â”€ content_factory.py        # Content generation factories
    â”œâ”€â”€ payment_factory.py        # Payment and subscription factories
    â”œâ”€â”€ roblox_factory.py         # Roblox integration factories
    â”œâ”€â”€ course_factory.py         # Course and lesson factories
    â”œâ”€â”€ agent_factory.py          # AI agent factories
    â””â”€â”€ notification_factory.py   # Notification factories
```

**Factory Example:**

```python
# tests/utils/factories/user_factory.py
import factory
from factory.fuzzy import FuzzyChoice, FuzzyText
from database.models import User
from datetime import datetime

class UserFactory(factory.alchemy.SQLAlchemyModelFactory):
    """Factory for creating test users"""

    class Meta:
        model = User
        sqlalchemy_session_persistence = "commit"

    # Basic fields
    id = factory.Faker('uuid4')
    email = factory.Faker('email')
    username = factory.LazyAttribute(lambda obj: obj.email.split('@')[0])
    first_name = factory.Faker('first_name')
    last_name = factory.Faker('last_name')

    # Authentication
    hashed_password = factory.LazyFunction(
        lambda: hash_password("SecurePass123!")
    )
    is_active = True
    email_verified = True

    # Role
    role = FuzzyChoice(['student', 'teacher', 'admin'])

    # Timestamps
    created_at = factory.LazyFunction(datetime.utcnow)
    updated_at = factory.LazyFunction(datetime.utcnow)

class AdminUserFactory(UserFactory):
    """Factory for admin users"""
    role = 'admin'
    permissions = ['all']

class TeacherUserFactory(UserFactory):
    """Factory for teacher users"""
    role = 'teacher'
    permissions = ['create_content', 'grade_assignments', 'view_analytics']

class StudentUserFactory(UserFactory):
    """Factory for student users"""
    role = 'student'
    permissions = ['view_content', 'submit_assignments']

# Usage in tests:
def test_user_creation():
    user = UserFactory()  # Creates random test user
    assert user.email is not None
    assert user.role in ['student', 'teacher', 'admin']

def test_admin_permissions():
    admin = AdminUserFactory()
    assert admin.role == 'admin'
    assert 'all' in admin.permissions

def test_batch_users():
    users = UserFactory.create_batch(10)  # Create 10 users
    assert len(users) == 10
```

**Effort:** 2 days
**Priority:** MEDIUM

---

### Deliverable 7: Coverage Reporting & CI/CD

**Goal:** Automate test coverage reporting in CI/CD pipeline

#### Files to Create:

```yaml
CI/CD Workflows:
  .github/workflows/
    â”œâ”€â”€ test-coverage.yml         # Coverage reporting
    â”œâ”€â”€ test-quality.yml          # Mutation testing
    â”œâ”€â”€ test-e2e.yml             # E2E testing
    â””â”€â”€ test-performance.yml      # Performance testing

Scripts:
  scripts/testing/
    â”œâ”€â”€ run_coverage.sh           # Local coverage script
    â”œâ”€â”€ generate_report.py        # Coverage report generator
    â”œâ”€â”€ upload_coverage.sh        # Upload to Codecov/Coveralls
    â””â”€â”€ check_thresholds.py       # Enforce coverage thresholds

Configuration:
  .coveragerc                     # Coverage configuration
  codecov.yml                     # Codecov configuration
```

**GitHub Actions Workflow:**

```yaml
# .github/workflows/test-coverage.yml
name: Test Coverage

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main, develop]

jobs:
  backend-coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest-cov pytest-xdist

      - name: Run tests with coverage
        run: |
          pytest --cov=apps/backend --cov=core --cov=database \
                 --cov-report=xml --cov-report=html --cov-report=term \
                 -n auto --maxfail=5

      - name: Check coverage threshold
        run: |
          python scripts/testing/check_thresholds.py \
            --threshold=80 --coverage-file=coverage.xml

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./coverage.xml
          flags: backend
          fail_ci_if_error: true

      - name: Upload coverage artifact
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage
          path: htmlcov/

  frontend-coverage:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Install dependencies
        run: |
          cd apps/dashboard
          npm install --no-bin-links --legacy-peer-deps

      - name: Run tests with coverage
        run: |
          cd apps/dashboard
          npm run test:coverage

      - name: Check coverage threshold
        run: |
          cd apps/dashboard
          npx vitest --coverage --reporter=json \
            | jq '.coverageMap | length'

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          file: ./apps/dashboard/coverage/coverage-final.json
          flags: frontend
          fail_ci_if_error: true

  coverage-report:
    needs: [backend-coverage, frontend-coverage]
    runs-on: ubuntu-latest
    steps:
      - name: Download backend coverage
        uses: actions/download-artifact@v4
        with:
          name: backend-coverage
          path: backend-coverage

      - name: Generate combined report
        run: |
          python scripts/testing/generate_report.py \
            --backend backend-coverage \
            --output combined-report.html

      - name: Comment PR with coverage
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('combined-report.html', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Test Coverage Report\n\n${report}`
            });
```

**Effort:** 1-2 days
**Priority:** MEDIUM

---

## ðŸ“‹ Implementation Timeline

### Week 1: Foundation (Days 1-3)

**Day 1: Testing Infrastructure**
- [x] Enhance pytest configuration
- [x] Set up coverage reporting
- [x] Create test utilities
- [x] Configure parallel testing

**Day 2-3: Test Data Factories**
- [x] Implement Factory Boy factories
- [x] Create fixture library
- [x] Set up database test utilities

### Week 2: Backend Testing (Days 4-8)

**Day 4-5: Router Tests**
- [x] Test content, analytics, admin routers
- [x] Test payment, notification routers
- [x] Test authentication routers

**Day 6-7: Service Tests**
- [x] Test content generation service
- [x] Test Roblox deployment service
- [x] Test analytics aggregation

**Day 8: Core Tests**
- [x] Test error handlers
- [x] Test permissions and rate limiting
- [x] Reach 80% backend coverage

### Week 3: Frontend & E2E (Days 9-13)

**Day 9-10: Component Tests**
- [x] Test AgentDashboard components
- [x] Test ContentGenerator components
- [x] Test PaymentForms components

**Day 11-12: E2E Tests**
- [x] Set up Playwright configuration
- [x] Implement user journey tests
- [x] Implement admin workflow tests

**Day 13: Integration Tests**
- [x] Test complete workflows
- [x] Test error recovery
- [x] Reach 75% frontend coverage

### Week 4: Error Handling & CI/CD (Days 14-16)

**Day 14: Error Handling**
- [x] Create custom exception hierarchy
- [x] Migrate critical paths (150 exceptions)
- [x] Implement retry strategies

**Day 15: CI/CD Setup**
- [x] Create GitHub Actions workflows
- [x] Configure Codecov integration
- [x] Set up coverage reporting

**Day 16: Documentation & Review**
- [x] Document testing patterns
- [x] Create error handling guide
- [x] Final review and cleanup

**Total Effort: 16 days** (can be parallelized with 2-3 developers to complete in 8-10 days)

---

## âœ… Success Metrics

### Coverage Targets

```yaml
Backend:
  Overall: â‰¥80%
  Critical Paths: 100%
  Routers: â‰¥85%
  Services: â‰¥80%
  Core: â‰¥90%

Frontend:
  Overall: â‰¥75%
  Components: â‰¥80%
  Hooks: â‰¥80%
  Integration: â‰¥75%

E2E:
  Critical User Flows: â‰¥50%
  Admin Workflows: â‰¥40%
  Error Scenarios: â‰¥30%
```

### Quality Targets

```yaml
Error Handling:
  Generic Exceptions: <100 (from 1,811)
  Custom Exceptions: >1,700
  Error Recovery: 100% of critical paths

Test Execution:
  Execution Time: <5 minutes
  Parallel Execution: Enabled
  Flaky Tests: <1%

CI/CD:
  Coverage Reports: Automated
  Threshold Enforcement: 80%
  PR Comments: Enabled
```

### Production Readiness

```yaml
Must Have:
  - âœ… 80% backend coverage
  - âœ… 75% frontend coverage
  - âœ… E2E tests for critical flows
  - âœ… <100 generic exceptions
  - âœ… Automated coverage reporting

Should Have:
  - âœ… Mutation testing
  - âœ… Performance testing
  - âœ… Load testing
  - âœ… Accessibility testing

Nice to Have:
  - â³ Visual regression testing (Session 1)
  - â³ Contract testing
  - â³ Chaos engineering
```

---

## ðŸš€ Getting Started

### Prerequisites

```bash
# Install testing dependencies
pip install pytest pytest-asyncio pytest-cov pytest-xdist factory-boy

# Frontend testing
cd apps/dashboard
npm install --save-dev @vitest/coverage-v8 @playwright/test

# Mutation testing
pip install mutmut
```

### Running Tests Locally

```bash
# Backend tests with coverage
pytest --cov=apps/backend --cov=core --cov-report=html -n auto

# Frontend tests with coverage
cd apps/dashboard && npm run test:coverage

# E2E tests
npx playwright test

# All tests
make test-all
```

### Viewing Coverage Reports

```bash
# Backend coverage
open htmlcov/index.html

# Frontend coverage
cd apps/dashboard && open coverage/index.html
```

---

## ðŸ“ Notes

### Testing Best Practices

1. **Write tests first** (TDD) for new features
2. **Test behavior, not implementation**
3. **Keep tests independent** and isolated
4. **Use descriptive test names**
5. **Mock external dependencies**
6. **Test edge cases and error paths**
7. **Maintain test data factories**
8. **Review test coverage regularly**

### Error Handling Principles

1. **Be specific** - Use custom exceptions
2. **Be informative** - Include error context
3. **Be recoverable** - Implement retry logic
4. **Be logged** - Track all errors
5. **Be user-friendly** - Return helpful messages
6. **Be secure** - Don't leak sensitive data

---

**Last Updated:** 2025-10-10
**Status:** Ready for execution
**Estimated Completion:** 16 days (or 8-10 days with team)
**Priority:** CRITICAL - Production Blocker
